import streamlit as st
import google.generativeai as genai
from google.api_core import exceptions

# 1. Configura√ß√£o Robusta
try:
    CHAVE = st.secrets["GEMINI_API_KEY"]
    genai.configure(api_key=CHAVE)
    
    # For√ßamos o uso do modelo est√°vel 1.5 Flash
    # Este modelo substitui o gemini-pro e o 3-flash-preview nas APIs est√°veis
    model = genai.GenerativeModel('gemini-1.5-flash')
    
    status_msg = "‚úÖ J√©ssica Cloud: Conectada"
    online = True
except Exception as e:
    status_msg = f"‚ùå Erro na Inicializa√ß√£o: {e}"
    online = False

st.set_page_config(page_title="J√©ssica - Flavors Flight", page_icon="ü§ñ")
st.title("ü§ñ J√©ssica: Intelig√™ncia de Pedidos")
st.caption("Sistema Flavors Flight Catering")

st.info(status_msg)

# Mem√≥ria Tempor√°ria (enquanto a aba estiver aberta)
if "memoria" not in st.session_state:
    st.session_state.memoria = {}

nome = st.text_input("üë§ Companhia A√©rea:")
pedido = st.text_area("üìã Detalhes do Pedido:", height=150)

if st.button("üöÄ Analisar com a J√©ssica"):
    if online and nome and pedido:
        with st.spinner('Acessando servidores do Google...'):
            hist = st.session_state.memoria.get(nome, "Primeiro pedido.")
            prompt = f"Voc√™ √© a J√©ssica da Flavors Flight. Analise o pedido de {nome}. Hist√≥rico: {hist}. Pedido: {pedido}."
            
            try:
                # Chamada direta e simplificada
                response = model.generate_content(prompt)
                
                st.markdown("---")
                st.subheader(f"üí° Resultado para {nome}")
                st.markdown(response.text)
                
                # Guarda na mem√≥ria
                st.session_state.memoria[nome] = response.text
                st.success("An√°lise memorizada nesta sess√£o.")
                
            except exceptions.NotFound:
                st.error("Erro 404: O modelo n√£o foi encontrado nesta regi√£o. Tentando alternativa...")
                # Tenta um modelo de backup caso o 1.5 Flash falhe
                model_backup = genai.GenerativeModel('gemini-1.5-flash-8b')
                response = model_backup.generate_content(prompt)
                st.markdown(response.text)
            except Exception as e:
                st.error(f"Erro t√©cnico: {e}")
    else:
        st.warning("Preencha os dados e verifique a conex√£o.")
